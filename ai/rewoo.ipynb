{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT=\"mikan\"\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class ReWOO(TypedDict):\n",
    "    # The initial task description\n",
    "    task: str\n",
    "\n",
    "    # The big-chunk plan string generated by the planner\n",
    "    plan_string: str\n",
    "\n",
    "    # The step-by-step plan extracted from plan_string\n",
    "    steps: List[str]\n",
    "\n",
    "    # Intermediate results after tool calls\n",
    "    results: dict # intermediate\n",
    "    result: str # autostart\n",
    "\n",
    "    # A list of file paths retrieved by the search tool\n",
    "    retrieved_docs: List[str]   \n",
    "\n",
    "    # The content generated by the autostart tool \n",
    "    autostart_content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "planner_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", google_api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"For the following task, make plans that can solve the problem step by step. For each plan, indicate \\\n",
    "# which external tool together with tool input to retrieve evidence. You can store the evidence into a \\\n",
    "# variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "# Tools can be one of the following:\n",
    "# (1) Google[input]: Worker that searches results from Google. Useful when you need to find short\n",
    "# and succinct answers about a specific topic. The input should be a search query.\n",
    "# (2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general\n",
    "# world knowledge and common sense. Prioritize it when you are confident in solving the problem\n",
    "# yourself. Input can be any instruction.\n",
    "\n",
    "# For example,\n",
    "# Task: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x\n",
    "# hours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours\n",
    "# less than Toby. How many hours did Rebecca work?\n",
    "# Plan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve\n",
    "# with Wolfram Alpha. #E1 = WolframAlpha[Solve x + (2x - 10) + ((2x - 10) - 8) = 157]\n",
    "# Plan: Find out the number of hours Thomas worked. #E2 = LLM[What is x, given #E1]\n",
    "# Plan: Calculate the number of hours Rebecca worked. #E3 = Calculator[(2 * #E2 - 10) - 8]\n",
    "\n",
    "# Begin! \n",
    "# Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "# Task: {task}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a068ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are MiKan, an advanced AI-powered productivity platform designed to revolutionize team workflows from meeting discussions to fully prepared, actionable tasks. Your core function is to act as an **intelligent workflow orchestrator and proactive information assistant**.\n",
    "\n",
    "Your capabilities include:\n",
    "\n",
    "1.  **Intelligent Query Generation for RAG:** For each identified task, you will proactively determine *all* the information and resources the assignee will need to immediately begin and successfully complete that task, even if not explicitly requested in the meeting.\n",
    "    * You will generate highly relevant, specific search queries for retrieval from the internal vector database (knowledge base).\n",
    "    * Prioritize explicit mentions (e.g., 'Product X brochure'), but also infer implicit needs based on task type, entities (e.g., 'new client in Germany' -> 'GDPR compliance'), and common pre-work steps for similar tasks.\n",
    "2.  **Proactive Information Retrieval & Synthesis ('Auto-Start'):**\n",
    "    * Utilize the generated queries to retrieve the most relevant documents, data snippets, and insights from the internal vector database.\n",
    "    * Synthesize this retrieved information into a concise, actionable format.\n",
    "    * This synthesized content should serve as the 'pre-start' package, directly embedded within the task for the assignee. This must include not only directly requested documents but also:\n",
    "        * Relevant policies, procedures, or compliance guidelines.\n",
    "        * Key insights or summaries from related reports.\n",
    "        * Templates or checklists that streamline the task.\n",
    "        * Contact information for relevant internal stakeholders or experts.\n",
    "    * Aim to provide information that mitigates 'cognitive blind spots' - knowledge the user might not even realize they need.\n",
    "\n",
    "**Persona & Principles:**\n",
    "\n",
    "* **Proactive & Anticipatory:** Always aim to provide information *before* it's asked for.\n",
    "* **Accurate & Contextual:** Ensure all extracted and retrieved information is highly relevant and precise to the task's specific context.\n",
    "* **Concise & Actionable:** Present information clearly, avoiding unnecessary verbosity, and making it directly usable for the task.\n",
    "* **Reliable & Trustworthy:** Strive for consistent, high-quality output that users can depend on.\n",
    "* **Security & Privacy Aware:** Understand that sensitive information may be handled; never generate or expose unauthorized data. (This is a high-level instruction; actual security is in your backend.)\n",
    "\n",
    "**Your ultimate goal is to eliminate 'pre-work friction' and ensure that every task generated from a meeting can be 'auto-started' efficiently and comprehensively.**\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "For the following task, make detailed plans that can solve the problem step by step. For each plan, indicate which external tool\n",
    "together with tool input to retrieve evidence. You can store the evidence into a variable #E that can be called by later tools. \n",
    "(Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "Tools can be one of the following:\n",
    "(1) RAG[input]: A retrieval tool that searches for relevant content from a MongoDB Vector Store, which acts as the internal knowledge base. \n",
    "The knowledge base contains the following relevant documents:\n",
    "{files_list}\n",
    "\n",
    "Use this when you need information that is not publicly available and must be retrieved from proprietary or internal documents, such as \n",
    "company reports, meeting transcripts, technical documentation, or internal guidelines. The input should be a natural language search query \n",
    "that clearly expresses the information you are looking for.\n",
    "(2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general\n",
    "world knowledge and common sense. Prioritize it when you are confident in solving the problem\n",
    "yourself. Input can be any instruction.\n",
    "\n",
    "For example,\n",
    "Task: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x\n",
    "hours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours\n",
    "less than Toby. How many hours did Rebecca work?\n",
    "Plan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve\n",
    "with Wolfram Alpha. #E1 = WolframAlpha[Solve x + (2x - 10) + ((2x - 10) - 8) = 157]\n",
    "Plan: Find out the number of hours Thomas worked. #E2 = LLM[What is x, given #E1]\n",
    "Plan: Calculate the number of hours Rebecca worked. #E3 = Calculator[(2 * #E2 - 10) - 8]\n",
    "\n",
    "Begin! \n",
    "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "Task: {task}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            user_prompt\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dba928",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | planner_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .gcs_list_files import list_gcs_files\n",
    "\n",
    "GCP_PROJECT_NAME = \"mikan01\"\n",
    "GCS_BUCKET_NAME = \"mikan-rag-source\"\n",
    "GCS_PREFIX = \"\" # Optional: set a prefix if you want to list files in a specific \"folder\"\n",
    "\n",
    "files_list = list_gcs_files(GCP_PROJECT_NAME, GCS_BUCKET_NAME, GCS_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Push Jumbo Rentals for at least a 10% cut on the sound system quote for the Dime Sarby car showcase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23454efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"files_list\": files_list, \"task\": task})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8626831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Regex to match expressions of the form E#... = ...[...]\n",
    "regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"user\", prompt)])\n",
    "planner = prompt_template | model\n",
    "\n",
    "\n",
    "def get_plan(state: ReWOO):\n",
    "    task = state[\"task\"]\n",
    "    result = planner.invoke({\"task\": task})\n",
    "    # Find all matches in the sample text\n",
    "    matches = re.findall(regex_pattern, result.content)\n",
    "    return {\"steps\": matches, \"plan_string\": result.content}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
